{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow --ignore-installed --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# # Load the image into a NumPy array\n",
    "# image_path = \"C:/Users/Saad/OneDrive - Institute of Business Administration/IBA code/6th Semester\\Parralel computing/RoadDetection/testing_data/verypoor_test.jpg\"\n",
    "# image_np = cv2.imread(image_path)\n",
    "\n",
    "# # Resize the image to the expected input size of the TensorFlow model\n",
    "# input_size = (224, 224)\n",
    "# image_np_resized = cv2.resize(image_np, input_size)\n",
    "\n",
    "#Use this to get image preprocessed\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the test image into a NumPy array\n",
    "image_path = \"C:/Users/Saad/OneDrive - Institute of Business Administration/IBA code/6th Semester\\Parralel computing/RoadDetection/testing_data/verypoor_test.jpg\"\n",
    "image_np = cv2.imread(image_path)\n",
    "\n",
    "# Resize the image to the expected input size of the TensorFlow model\n",
    "input_size = (224, 224)\n",
    "image_np_resized = cv2.resize(image_np, input_size)\n",
    "\n",
    "# Scale the pixel values to the range [0, 1]\n",
    "image_np_resized = image_np_resized / 255.0\n",
    "\n",
    "# Add a batch dimension to the image array\n",
    "image_np_resized = np.expand_dims(image_np_resized, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "# Create a SparkSession object\n",
    "spark = SparkSession.builder.appName(\"RoadPrediction\").getOrCreate()\n",
    "\n",
    "# Convert the resized image to a vector\n",
    "image_vec = Vectors.dense(image_np_resized.flatten())\n",
    "\n",
    "# Create a PySpark DataFrame containing a single row with the image vector\n",
    "image_df = spark.createDataFrame([(image_vec,)], [\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sparkdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "import sparkdl as sdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkdl import TFModel\n",
    "\n",
    "# Specify the paths to the model files and the input/output node names\n",
    "model_path = \"C:/Users/Saad/OneDrive - Institute of Business Administration/IBA code/6th Semester/Parralel computing/RoadDetection/saved_model/saved_model.pb\"\n",
    "input_node_name = \"input_features\"\n",
    "output_node_name = \"output_scores\"\n",
    "\n",
    "# Load the TensorFlow model in PySpark\n",
    "tf_model = TFModel(modelPath=model_path,\n",
    "                   inputCol=input_node_name,\n",
    "                   outputCol=output_node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.ml.linalg import Vectors\n",
    "\n",
    "# # Create a SparkSession object\n",
    "# spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n",
    "\n",
    "# def predict_profile(image_path, model):\n",
    "#     print(\"Predicting .................................\")\n",
    "#     ar = convert_to_array(image_path)\n",
    "#     ar = ar / 255\n",
    "#     image_vec = Vectors.dense(ar.flatten())\n",
    "#     image_df = spark.createDataFrame([(image_vec,)], [\"features\"])\n",
    "#     predictions = model.transform(image_df)\n",
    "#     label_index = np.argmax(predictions.collect()[0]['output_scores'])\n",
    "#     profile = get_profile_name(label_index)\n",
    "#     acc = predictions.collect()[0]['output_scores'][label_index]\n",
    "#     print(\"The predicted profile is a \" + profile + \" with accuracy = \" + str(acc))\n",
    "#     return predictions\n",
    "\n",
    "# # Example usage:\n",
    "# model_path = \"/path/to/extracted/model\"\n",
    "# input_node_name = \"input_features\"\n",
    "# output_node_name = \"output_scores\"\n",
    "# model = load_pretrained_model(model_path, input_node_name, output_node_name)\n",
    "# test_image_path = \"/path/to/test_image.jpg\"\n",
    "# predictions = predict_profile(test_image_path, model)\n",
    "# predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "from tensorflow import keras\n",
    "from tensorflow.compat.v1.saved_model import load as tf_load_model\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the TensorFlow Keras pretrained model in the form of a .pb file:\n",
    "# tf_model = tf.saved_model.load(\"C:/Users/Saad/OneDrive - Institute of Business Administration/IBA code/6th Semester/Parralel computing/RoadDetection/saved_model\",  tags=[\"serve\"], export_dir='')\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], \"C:/Users/Saad/OneDrive - Institute of Business Administration/IBA code/6th Semester/Parralel computing/RoadDetection/saved_model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(x):\n",
    "    input_tensor = tf_model.signatures[\"serving_default\"].inputs[\"input_1\"]\n",
    "    output_tensor = tf_model.signatures[\"serving_default\"].outputs[\"output_1\"]\n",
    "    prediction = tf_model(input_tensor=tf.cast(x, dtype=tf.float32))[output_tensor].numpy()\n",
    "    return np.argmax(prediction)\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType, ArrayType\n",
    "\n",
    "# Define a UDF that applies the pre-trained model to each row of the DataFrame\n",
    "predict_udf = udf(predict_fn, IntegerType())\n",
    "\n",
    "from pyspark.sql.types import DoubleType, ArrayType\n",
    "\n",
    "# Define the element type of the array\n",
    "element_type = DoubleType()\n",
    "\n",
    "# Create an ArrayType with the specified element type\n",
    "array_type = ArrayType(element_type)\n",
    "\n",
    "# Apply the UDF to the test DataFrame to get the predicted label for each image\n",
    "predicted_df = image_df.withColumn(\"predicted_label\", predict_udf(image_df[\"features\"].cast(array_type)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
